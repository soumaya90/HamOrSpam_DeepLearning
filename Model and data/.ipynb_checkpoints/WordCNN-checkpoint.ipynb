{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import *\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for reproducible results\n",
    "from numpy.random import seed\n",
    "seed(302)\n",
    "import tensorflow \n",
    "tensorflow.random.set_seed(302)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df=pd.read_csv('SMSSpamCollection',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables\n",
    "sms_df=sms_df.rename(columns={0: 'Labels', 1: 'Text'})\n",
    "\n",
    "# create binary where 1 = spam and 0 = ham\n",
    "sms_df['Labels_Binary'] = 0\n",
    "sms_df.loc[sms_df['Labels']=='spam', 'Labels_Binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = sms_df['Text']\n",
    "labels = sms_df['Labels_Binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition data into train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train/test sample\n",
    "other_texts, test_texts, other_labels, test_labels  = train_test_split(texts, labels, test_size=0.1, random_state=302)\n",
    "#Create validation sample\n",
    "train_texts, valid_texts, train_labels, valid_labels  = train_test_split(other_texts, other_labels, test_size=0.2, random_state=302)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate ham/spam breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cases_count = labels.value_counts(dropna=False)\n",
    "        \n",
    "# Plot  results \n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x=cases_count.index, y=cases_count.values)\n",
    "plt.ylabel('Texts', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Ham', 'Spam'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary size (you can tune this parameter and evaluate model performance)\n",
    "VOCABULARY_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input feature arrays\n",
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "# Convert words into word ids\n",
    "meanLength = np.mean([len(item.split(\" \")) for item in train_texts])\n",
    "MAX_SENTENCE_LENGTH = int(meanLength + 5) # we let a text go 10 words longer than the mean text length.\n",
    "\n",
    "# Convert train, validation, and test text into lists with word ids\n",
    "trainFeatures = tokenizer.texts_to_sequences(train_texts)\n",
    "trainFeatures = pad_sequences(trainFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "trainLabels = train_labels.values\n",
    "\n",
    "validFeatures = tokenizer.texts_to_sequences(valid_texts)\n",
    "validFeatures = pad_sequences(validFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "validLabels = valid_labels.values\n",
    "\n",
    "testFeatures = tokenizer.texts_to_sequences(test_texts)\n",
    "testFeatures = pad_sequences(testFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "testLabels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use this hardcoded sentence length in the prep for the flask app\n",
    "MAX_SENTENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filter and kernel size for CNN (can adjust in tuning model)\n",
    "FILTERS_SIZE = 16\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "# Define embeddings dimensions (columns in matrix fed into CNN and nodes in hidden layer of built-in keras function)\n",
    "EMBEDDINGS_DIM = 10\n",
    "\n",
    "# Hyperparameters for model tuning\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 20, 10)            50010     \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 16, 16)            816       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16, 16)            0         \n",
      "                                                                 \n",
      " global_max_pooling1d_7 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,971\n",
      "Trainable params: 50,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Word CNN\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We use built-in keras funtion to generate embeddings. Another option is pre-trained embeddings with Word2vec or GloVe.\n",
    "model.add(Embedding(input_dim=VOCABULARY_SIZE + 1, output_dim=EMBEDDINGS_DIM, input_length=len(trainFeatures[0])))\n",
    "model.add(Conv1D(FILTERS_SIZE, KERNEL_SIZE, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            \n",
    "optimizer =tf.keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "126/126 [==============================] - 2s 8ms/step - loss: 0.4122 - accuracy: 0.8494 - val_loss: 0.2986 - val_accuracy: 0.8694\n",
      "Epoch 2/7\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.2338 - accuracy: 0.9155 - val_loss: 0.2185 - val_accuracy: 0.9671\n",
      "Epoch 3/7\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.1245 - accuracy: 0.9698 - val_loss: 0.1333 - val_accuracy: 0.9801\n",
      "Epoch 4/7\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.0814 - accuracy: 0.9796 - val_loss: 0.0965 - val_accuracy: 0.9840\n",
      "Epoch 5/7\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 0.0593 - accuracy: 0.9875 - val_loss: 0.0838 - val_accuracy: 0.9840\n",
      "Epoch 6/7\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.0773 - val_accuracy: 0.9831\n",
      "Epoch 7/7\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 0.0716 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainFeatures, trainLabels, validation_data = (validFeatures, validLabels), batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-acc237b1ac20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# summarize accuracy by epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "# summarize accuracy by epoch\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get examples from embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0ec69852fa52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_activations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainFeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   4316\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4317\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_utils\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4318\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4320\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;31m# This feature is only enabled in TF2 not in v1 graph mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0m\u001b[0;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;31m# This feature is only enabled in TF2 not in v1 graph mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0m\u001b[0;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional_utils.py\u001b[0m in \u001b[0;36mis_input_keras_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     45\u001b[0m   \"\"\"\n\u001b[0;32m     46\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 0"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[0].output,])\n",
    "activations = get_activations([trainFeatures,0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>Yo we are watching a movie on netflix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Text\n",
       "2758  Yo we are watching a movie on netflix"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(train_texts).iloc[[113]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures[113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(activations[113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict binary and probabilities\n",
    "predictions_df = pd.DataFrame(model.predict(testFeatures))\n",
    "predictions_binary_df = round(predictions_df)\n",
    "accuracy_score(testLabels, predictions_binary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_binary_df[0].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model architecture and pre-trained weights for Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to the directory with flask app\n",
    "current_dir = os.getcwd()\n",
    "output_dir = re.sub('Model and data', 'Flask application', current_dir)\n",
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokenizer for preprocessing\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON for Flask App\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
